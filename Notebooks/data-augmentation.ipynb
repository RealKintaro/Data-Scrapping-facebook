{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline\nimport random\n\nunmasker = pipeline('fill-mask', model='aubmindlab/bert-base-arabertv02')\n\ninput_text = \"مش معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\"\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-05T15:10:32.689084Z","iopub.execute_input":"2023-01-05T15:10:32.689532Z","iopub.status.idle":"2023-01-05T15:11:40.634229Z","shell.execute_reply.started":"2023-01-05T15:10:32.689498Z","shell.execute_reply":"2023-01-05T15:11:40.632949Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8d0c03117d447ea8d61dbb16ab04f5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/381 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aadcd4c50fb44bc8b374424c9a19d68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/805k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11cdf9794d98439c8e179b3f99b20e4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9a3cc3944c4f7b95e95e777e5179bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bc78137d92e475db07459a619c6b21b"}},"metadata":{}},{"name":"stdout","text":"Masked sentence-> مش معقول مفتي السعوديه اكبر دوله [MASK] سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\nAugmented text-> مش معقول مفتي السعوديه اكبر دوله بالعالم سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv(\"/kaggle/input/test-tweets/tweets_test.csv\", encoding='utf-16')\ntrain = train.iloc[:5]\n","metadata":{"execution":{"iopub.status.busy":"2023-01-05T16:02:42.723334Z","iopub.execute_input":"2023-01-05T16:02:42.723721Z","iopub.status.idle":"2023-01-05T16:02:42.739367Z","shell.execute_reply.started":"2023-01-05T16:02:42.723690Z","shell.execute_reply":"2023-01-05T16:02:42.738022Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-05T16:11:17.717001Z","iopub.execute_input":"2023-01-05T16:11:17.717479Z","iopub.status.idle":"2023-01-05T16:11:17.728734Z","shell.execute_reply.started":"2023-01-05T16:11:17.717442Z","shell.execute_reply":"2023-01-05T16:11:17.727815Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                   id                                              tweet\n0  958390144494694400  اخطر اعداء الامه منافقوها ينشغلون بتشويه مصلحي...\n1  958390531867971584  حتي مارك اليهودي يحب مخرجات مءتمر الخوار الوطن...\n2  958390679780016129  gcc تصوير جوي لحصن مرحب في خيبر الذي فتحه النب...\n3  958390811514822656  خدمات الكنيسه ماشيين مع بعض بمبدا اليهود لا يع...\n4  958390828682096640  ذكر الله المنافقين اكثر من اليهود لانهم يستعمل...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>958390144494694400</td>\n      <td>اخطر اعداء الامه منافقوها ينشغلون بتشويه مصلحي...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>958390531867971584</td>\n      <td>حتي مارك اليهودي يحب مخرجات مءتمر الخوار الوطن...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>958390679780016129</td>\n      <td>gcc تصوير جوي لحصن مرحب في خيبر الذي فتحه النب...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>958390811514822656</td>\n      <td>خدمات الكنيسه ماشيين مع بعض بمبدا اليهود لا يع...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>958390828682096640</td>\n      <td>ذكر الله المنافقين اكثر من اليهود لانهم يستعمل...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"orig_text_list = input_text.split()\nlen_input = len(orig_text_list)\nrand_idx = random.randint(1,len_input-2)\nrand_idx2 = random.randint(1,len_input-2)\n\nnew_text_list = orig_text_list[:rand_idx] + ['[MASK]'] + orig_text_list[rand_idx:]\nnew_mask_sent = ' '.join(new_text_list)\nprint(\"Masked sentence->\",new_mask_sent)\n\naugmented_text_list = unmasker(new_mask_sent)\naugmented_text = augmented_text_list[0]['sequence']\n\naugmented_text = augmented_text.split()\n\nnew_text_list = augmented_text[:rand_idx2] + ['[MASK]'] + augmented_text[rand_idx2:]\nnew_mask_sent = ' '.join(new_text_list)\n\naugmented_text_list = unmasker(new_mask_sent)\naugmented_text = augmented_text_list[0]['sequence']\n\nprint(\"Augmented text->\",augmented_text)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:19:02.196844Z","iopub.execute_input":"2023-01-05T15:19:02.197309Z","iopub.status.idle":"2023-01-05T15:19:02.483283Z","shell.execute_reply.started":"2023-01-05T15:19:02.197272Z","shell.execute_reply":"2023-01-05T15:19:02.480102Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Masked sentence-> مش [MASK] معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\nAugmented text-> مشي معقول مفتي السعوديه اكبر دوله سنيه بالعالم يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"مش معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\"\n\norig_text_list = input_text.split()\nlen_input = len(orig_text_list)\n#Random index where we want to replace the word \nrand_idx = random.randint(1,len_input-1)\norig_word = orig_text_list[rand_idx]\nnew_text_list = orig_text_list.copy()\nnew_text_list[rand_idx] = '[MASK]'\nnew_mask_sent = ' '.join(new_text_list)\nprint(\"Masked sentence->\",new_mask_sent)\n#I went to [MASK] a movie in the theater\n\naugmented_text_list = unmasker(new_mask_sent)\n#To ensure new word and old word are not name\nfor res in augmented_text_list:\n    if res['token_str'] != orig_word:\n        augmented_text = res['sequence']\n        break\nprint(\"Augmented text->\",augmented_text)\n#I went to watch a movie in the theater","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:20:43.203740Z","iopub.execute_input":"2023-01-05T15:20:43.204199Z","iopub.status.idle":"2023-01-05T15:20:43.328256Z","shell.execute_reply.started":"2023-01-05T15:20:43.204163Z","shell.execute_reply":"2023-01-05T15:20:43.327076Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Masked sentence-> مش معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه [MASK] لطفك بنا يارب\nAugmented text-> مش معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه يارب لطفك بنا يارب\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\ngenerator = pipeline('text-generation', model='gpt2')\n\ninput_text = \"I went to see a movie in the theater\"\ninput_length = len(input_text.split())\nnum_new_words = 10\noutput_length = input_length + num_new_words\ngpt_output = generator(input_text, max_length=output_length, num_return_sequences=5)\naugmented_text = gpt_output[0]['generated_text']\nprint(\"Augmented text->\",augmented_text)\n#I went to see a movie in the theater, and the director was","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:50:24.712477Z","iopub.execute_input":"2023-01-05T15:50:24.712937Z","iopub.status.idle":"2023-01-05T15:50:40.010671Z","shell.execute_reply.started":"2023-01-05T15:50:24.712882Z","shell.execute_reply":"2023-01-05T15:50:40.009404Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Augmented text-> I went to see a movie in the theater. I knew him. I was afraid of this\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"مش معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا يارب\"\ninput_length = len(input_text.split())\nnum_new_words = 10\noutput_length = input_length + num_new_words\ngpt_output = generator(input_text, max_length=output_length, num_return_sequences=5)\naugmented_text = gpt_output[0]['generated_text']\nprint(\"Augmented text->\",augmented_text)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:50:54.349939Z","iopub.execute_input":"2023-01-05T15:50:54.350376Z","iopub.status.idle":"2023-01-05T15:50:55.603340Z","shell.execute_reply.started":"2023-01-05T15:50:54.350341Z","shell.execute_reply":"2023-01-05T15:50:55.602110Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nInput length of input_ids is 103, but ``max_length`` is set to 27. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","output_type":"stream"},{"name":"stdout","text":"Augmented text-> مش معقول مفتي السعوديه اكبر دوله سنيه يفتي بمسانده اليهود والوزير الصهيوني يدعوه للزياره لطفك بنا ياربي\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/test-tweets-df/test_tweets.csv', encoding='utf-16')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T16:55:38.605312Z","iopub.execute_input":"2023-01-05T16:55:38.606394Z","iopub.status.idle":"2023-01-05T16:55:38.641046Z","shell.execute_reply.started":"2023-01-05T16:55:38.606348Z","shell.execute_reply":"2023-01-05T16:55:38.640255Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                   id                                              tweet  hate\n0  958390144494694400  اخطر اعداء الامه منافقوها ينشغلون بتشويه مصلحي...     1\n1  958390531867971584  حتي مارك اليهودي يحب مخرجات مءتمر الخوار الوطن...     0\n2  958390679780016129  gcc تصوير جوي لحصن مرحب في خيبر الذي فتحه النب...     0\n3  958390811514822656  خدمات الكنيسه ماشيين مع بعض بمبدا اليهود لا يع...     0\n4  958390828682096640  ذكر الله المنافقين اكثر من اليهود لانهم يستعمل...     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>958390144494694400</td>\n      <td>اخطر اعداء الامه منافقوها ينشغلون بتشويه مصلحي...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>958390531867971584</td>\n      <td>حتي مارك اليهودي يحب مخرجات مءتمر الخوار الوطن...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>958390679780016129</td>\n      <td>gcc تصوير جوي لحصن مرحب في خيبر الذي فتحه النب...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>958390811514822656</td>\n      <td>خدمات الكنيسه ماشيين مع بعض بمبدا اليهود لا يع...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>958390828682096640</td>\n      <td>ذكر الله المنافقين اكثر من اليهود لانهم يستعمل...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\n\ndf = pd.DataFrame()\n# Iterate over the rows in the dataframe\nfor index, row in train.iterrows():\n  #Encode the text input as a BERT input\n    input_text = row['tweet']\n    \n    orig_text_list = input_text.split()\n    len_input = len(orig_text_list)\n    rand_idx = random.randint(1,len_input-2)\n    rand_idx2 = random.randint(1,len_input-2)\n\n    new_text_list = orig_text_list[:rand_idx] + ['[MASK]'] + orig_text_list[rand_idx:]\n    new_mask_sent = ' '.join(new_text_list)\n    print(\"Masked sentence->\",new_mask_sent)\n\n    augmented_text_list = unmasker(new_mask_sent)\n    augmented_text = augmented_text_list[0]['sequence']\n\n    augmented_text = augmented_text.split()\n\n    new_text_list = augmented_text[:rand_idx2] + ['[MASK]'] + augmented_text[rand_idx2:]\n    new_mask_sent = ' '.join(new_text_list)\n\n    augmented_text_list = unmasker(new_mask_sent)\n    augmented_text = augmented_text_list[0]['sequence']\n  # Add the generated text to the dataframe\n    df = df.append({'tweet': augmented_text, 'hate': row['hate']}, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T16:55:43.996367Z","iopub.execute_input":"2023-01-05T16:55:43.997166Z","iopub.status.idle":"2023-01-05T16:56:03.259504Z","shell.execute_reply.started":"2023-01-05T16:55:43.997122Z","shell.execute_reply":"2023-01-05T16:56:03.257431Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Masked sentence-> اخطر اعداء الامه منافقوها ينشغلون بتشويه مصلحيها ليضعفوهم ويسكتون عن مفسديها ليقووهم كانوا يسخرون من الصحابه ويسكتون عن يهود المدينه فلاجل ذلك حاربوا الصحوه لاجل هذا [MASK] حاربوا الصحوه\nMasked sentence-> حتي مارك [MASK] اليهودي يحب مخرجات مءتمر الخوار الوطني قبل قليل ارسل لي رساله تم اعاده تغيير صورتك الشخصيه الي الصوره\nMasked sentence-> gcc تصوير جوي لحصن مرحب في خيبر الذي فتحه النبي صلي الله عليه وسلم [MASK] في معركه خيبر وكان مقر اليهود بعد اجلاءهم من المدينه المنوره\nMasked sentence-> خدمات [MASK] الكنيسه ماشيين مع بعض بمبدا اليهود لا يعاملون السامريين\nMasked sentence-> ذكر الله المنافقين [MASK] اكثر من اليهود لانهم يستعملون وساءل شرعيه لهدم الاصول ويخفون علي العامه فاعين البسطاء علي الوساءل واعينهم علي الاهداف ف لاجل هذا حاربوا الصحوه\nMasked sentence-> انتم المصافحون العملاء من تلطخت يده يوما بمصافحه اليهود لن يكون صهره انظف منه فالطيور علي اشكالها تقع [MASK] البلطجي جبران قزم العهد\nMasked sentence-> استهداف السعوديه واضح ٠ المسلم يذهب سنويا للحج وشهريا للعمره وينزل بمطارات علي مستوي متقدم ويسكن [MASK] بارقي الفنادق بسهوله ويسر ٠ بينما لايستطيع الذهاب للاقصي الذي يتحكم به اليهود وتغلق ابوابه امام المسلمين ٠ وتجد ايران والعصملي يطالبون بتدويل الحرمين ولم يطالبوا بتدويل الاقصي\nMasked sentence-> من علامات المنافقين اتفاق اهدافهم مع اهداف اليهود والنصاري الم تر الي الذين نافقوا يقولون لاخوانهم الذين كفروا من اهل الكتاب [MASK] الا تتفق اعداء محاربي الدين مع اهداف امريكا اليسوا خونه للدين والوطن ف لاجل هذا حاربوا الصحوه\nMasked sentence-> كان المنافقون مع قلتهم زمن النبي سببا في تاخر النصر علي اليهود واليوم يتاخر النصر اكثر لان المنافقين اكثر من اليهود لاجل هذا [MASK] حاربوا الصحوه\nMasked sentence-> رغم ماقيل عنها اسيوط بلد اليهود الا ان فيها من نحب ومن نستامن ومن يءلمنا المه ومن نلجا اليه [MASK] عند الحاجه اسيوط\nMasked sentence-> البراكين تغلي بصدر كل يمني حر الله اكبر [MASK] الموت لامريكا الموت لاسراءيل اللعنه علي اليهود النصر للاسلام\nMasked sentence-> مستشارين [MASK] ايرانيين ولهم خدم من لبنان وزنابيل من اليمن ودعم قطري كلها لرفع رايه الخمينيه حمير اليهود لاحوثي بعد اليوم\nMasked sentence-> وشهد شاهد من اهلها اليهودي [MASK] عباس اسمع وافهم\nMasked sentence-> الصهيونيه [MASK] شكل من اشكال العنصريه بولندا تخضع للابتزاز الصهيوني و توافق علي تعديل قانون كانت ستصدره ينفي تورط بولندا فيما يسمي محرقه اليهود\nMasked sentence-> منهو اليهودي الي [MASK] لعب علينا وقال انه هداف العالم النصر التعاون\nMasked sentence-> الله اك بر الموت لامريكا الموت [MASK] لاسراءيل اللعنه علي اليهود النصر للاسلام الله اك بر الموت لامريكا الموت لاسراءيل اللعنه علي اليهود النصر للاسلام الله اك بر الموت لامريكا الموت لاسراءيل اللعنه علي اليهود النصر للاسلام امريكا واسراءيل اعداءنا\nMasked sentence-> يا اوسخ اسم ف الوجود دراويش [MASK] جمهوركوا اوسخ م اليهود دراويش هنعيش دراويش ونموت دروايش دراويش كسم الدراويش اووووه اووووه كسم اسماعيليه بلدكوا\nMasked sentence-> كل ما [MASK] ترونه وتلمسونه في امتنا الاسلاميه جعله الله صنيعه اليهود فينا\nMasked sentence-> الاخوان يمهدون اخرجوا الكفار من جزيره العرب والمنظرين ممن يدعون انهم طلبه علم انخدعوا وانقادوا خلف الاخوان فغرروا [MASK] بشباب ليندفعون للقتال في صفوف القاعده وداعش وغيرها من العصابات الاخوان يعملوا لخدمه الخمينيه حمير اليهود تنظيم الحمدين\nMasked sentence-> ارسنال جيغو ب 18 مليون قسم بالله قهر واداره بالبيع بنت يهود لاهم اللي يشرون صح ولاهم يبيعون [MASK] صح اوضع مدافع انجليزي ماتحصله بهالمبلغ\nMasked sentence-> الله يخلف علي كل من لايزال منكم مصدق ان اليهود [MASK] يزرعون نبات الغرقد ليختبءوا خلفه من المسلم الذي سيقتلهم رغم علمهم ان الشجره سوف تتكلم وتخبر بمكانهم\nMasked sentence-> خدعوك فقالوا ابن [MASK] القيم قال ان الشيعه اشد خطرا علي الاسلام من اليهود بكل اسف تم تسويق هذا الكلام\nMasked sentence-> خدعوك فقالوا ابن القيم قال ان الشيعه اشد خطرا علي [MASK] الاسلام من اليهود بكل اسف تم تسويق هذا الكلام\nMasked sentence-> خدعوك فقالوا ابن القيم قال ان الشيعه اشد خطرا علي الاسلام من اليهود بكل اسف تم [MASK] تسويق هذا الكلام\nMasked sentence-> خدعوك فقالوا ابن القيم قال ان الشيعه اشد خطرا علي الاسلام من اليهود بكل اسف [MASK] تم تسويق هذا الكلام\nMasked sentence-> اما والله لو عاد فيه اثنين رءسا دول اسلاميه مثل الرءيس التركي اوردغان ان لا يحرقوا اليهود من [MASK] العالم حريق اما مثل الرءسا حقون الدول العربيه المنافقين فعلي الدنيا العوض\nMasked sentence-> الله يلعن ريبروف ووليد باخشوين [MASK] لعنه اليهود والنصاري والمنافقين\nMasked sentence-> قال رسول الله يتبع الدجال من يهود اصبهان سبعون الفا عليهم الطيالسه رياض الصالحين تاملات [MASK] تاملات تويت\nMasked sentence-> لم يستهدف اليهود هذا الاسلام بالتحديد لانهم يعرفون من تاريخهم انهم مهزمون [MASK] من هذا الدين يوما ما وان تربعوا علي عرش الدنيا لسنوات طواااال\nMasked sentence-> الله اكبر الموت لامريكا الموت لاسراءيل اللعنه علي اليهود النصر للاسلام الله اكبر الموت لامريكا الموت [MASK] لاسراءيل اللعنه علي اليهود النصر للاسلام الله اكبر الموت لامريكا الموت لاسراءيل اللعنه علي اليهود النصر للاسلام\nMasked sentence-> وعلماء نجد والقصيم والدعوه قبل خمسين عام وبعضهم اليوم وعلماء اليهود والمسيحيين قبل ميه عام وبعضهم اليوم يءيدون ما يقوله متعب وكلماتك جمله وتفصيلا ينكرون علم الفلك وعلم [MASK] الطب اليوم وما تقوله ناسا وان المطر من الشمس والبحر جمله وتفصيلا\nMasked sentence-> مجرمي الحرب الحقيقين هم انتم ايها الانجليز فاسلافكم السفله ساعدوا اليهود في [MASK] احتلال فلسطين ومعاناتهم طوال 60 عاما\nMasked sentence-> مايصير ريال معاشه ١٢٠٠ تطلبين منه جنطه ب ٥٠٠٠ يا بنت اليهودي الريال بيقعد [MASK] جم شهر يجمع عشان تكشخين علي افاه يا ام راس مربع\nMasked sentence-> لان مسلمي تركستان ليسوا يهود ولا نصاري فلا بواكي وهكذا يفعل [MASK] باهل الايمان في غالب بقاع الارض\nMasked sentence-> ليالي اسطنبول القاءمين [MASK] علي هيءه الترفيه ما يعرفون اتراك وسعوديين ولا تاريخ ولا دين المهم عندهم كيف يرقصون ياكلون من اموال الهيءه واحلال المجتمع عجبا كيف اتخذناكم اصدقاء كنا نخشا علي الدين والعرض من اليهود وابتلشنا بالمتهودين\nMasked sentence-> قناه اليهود الOTV تتمادي في مقدمه نشرتها بحق رمز الوطن [MASK] والوحده الوطنيه الاستاذ نبيه بري فبعد كلام القزيم باسيل وبيان العهد الفارغ نقول لمن فر هاربا خلال 47 دقيقه تاركا وراءه مناصريه وعاءلته نقول لمن وصل الي منصب الرءاسه بدعم من البلطجيه سوف تندمون عهد الزعاطيط\nMasked sentence-> ريفاس ما انسجم مع خريبين ومع مختار ومع مجاهد ابن اليهوديه ذا يبغي [MASK] يلعب بالنادي لوحده\nMasked sentence-> النصيريه استخدموه [MASK] في الشام وهم كما وصفهم بن تيميه رحمه الله اكفر واشر من اليهود والنصاري\nMasked sentence-> الاهلي الشباب يا [MASK] الله انك تلعن فيتفا لعنه اليهود والنصاري\nMasked sentence-> من الفرحه و بعد اعلان رفض قرار [MASK] ترامب اليهودي الامريكي دبكه فلسطينيه في قلب مقر الامم المتحده بنيويورك\nMasked sentence-> انقذوا معتقلي الحريه استخدام العسكر وتفننهم في التخلص من علماء الامه وافضل ماانجبت مصر لصالح اليهود لتفريغ الامه من [MASK] طاقاتها الفعاله\nMasked sentence-> ابو [MASK] علي علي شنو تبارك لهم نسيت هذولا شنو سووا هم والناطق الاعلامي السابق مالهم تري مانسينا اليهود\nMasked sentence-> نقاب [MASK] بعض طواءف اليهود لعبيد الغرب الله يخلصنا من حقدهم وجهلهم\nMasked sentence-> ال ل ه اك ب ر ال م وت لام ري ك ا [MASK] ال م وت لاس راء ي ل ال ل ع ن ه ع ل ي ال ي ه ود ال ن ص ر ل لاس لام\nMasked sentence-> فواءد برنامج مهمات العلم١٤٣٩ ذكر [MASK] لنا في شرح الاربعين معلومه قال انها تساوي رحله وهي ان ابن حجر قال ثبت من خلال استقراء الاحاديث انه اذا وردت من كان قبلكم في الامور الدينيه فالمقصود بها اليهود والنصاري وفي الامور الدنياويه فالمقصود بها فارس والروم\nMasked sentence-> صهاينه الامارات [MASK] يدعموالانقلاب وال يهود يدعموهم\nMasked sentence-> حاسبوا امير موسوي هو يعتقد انه علي حق مءوسس المذهب [MASK] الشيعي هو اليهودي عبدالله بن سبا والبدعه تتفرق\nMasked sentence-> حاسبوا امير موسوي هو يعتقد انه علي حق مءوسس المذهب الشيعي هو اليهودي [MASK] عبدالله بن سبا والبدعه تتفرق\nMasked sentence-> حاسبوا امير موسوي هو يعتقد انه علي حق مءوسس المذهب الشيعي هو اليهودي عبدالله بن سبا [MASK] والبدعه تتفرق\nMasked sentence-> حاسبوا [MASK] امير موسوي هو يعتقد انه علي حق مءوسس المذهب الشيعي هو اليهودي عبدالله بن سبا والبدعه تتفرق\nMasked sentence-> العبايه تقليد الحريديم اليهوديه جميع الديانات السماويه من الله امر بها ستر المراه يعني طرتن وقعتن الدين واحد والرب واحد وشرعه مستحيل يتغير ويمكن ذا اليهوديات باقيات علي نتفه صحيحه من تعاليم الشريعه اللي نزلت [MASK] ع موسي\nMasked sentence-> كشفت صحيفه هارتس الاسراءيليه ان امير قطر تميم العار التقي زعيم المنظمه [MASK] الصهيونيه الاميركيه في الدوحه في اطار حمله قطريه من اجل نيل دعم اللوبي اليهودي في الولايات المتحده لتخفيف الضغط عليها فيما يتعلق بملف دعمها للارهاب والمنظمات الارهابيه قطر تمول الارهاب\nMasked sentence-> العبايه تقليد الحريديم اليهوديه الستر زين حتي لو كان له ضراءب من كثر اقمشه وغيره برضو زين [MASK] احسن من اللي واضحه معالم صدرها ومقفاها كانها بضاعه تعرضها لكل من هب ودب والكل ينظر لها باحتقار\nMasked sentence-> الله يلعن [MASK] ريفاس ستين لعنه ولد اليهود\nMasked sentence-> مبروك [MASK] اليهود هاردلك الدياي\nMasked sentence-> قطر تواصل استقبال قاده اليهود الداعمين للمستوطنات الاسراءيليه [MASK] دون خجل نظام الحمدين قطر تنظيم الحمدين\nMasked sentence-> والله عيب فريقنا [MASK] معوق خلقه تستقعد لنا بالحكام الملاعين اليهود الخنازير\nMasked sentence-> بس ريال عن عبدالله بن عباس رضي الله عنه [MASK] قال قال النبي لعن الله اليهود ثلاثا ان الله حرم عليهم الشحوم فباعوها واكلوا اثمانها وان الله اذا حرم علي قوم اكل شيء حرم عليهم ثمنه رواه ابو داود 3488 وصححه الالباني\nMasked sentence-> لا لخلط الاسلام بالسياسه نعم لخلط المسيحيه بالسياسه منطق [MASK] اعوج يتبناه علمانيونا\nMasked sentence-> انا سعودي بالله عليكم لو نيوتن بدوي كان يوم طاحت التفاحه قال طاح قلبي في هوي زين الوصايف مثل [MASK] تفاحتن علي الرمضا تط يحي وخلصنا لا فيزياء ولا كيمياء ولا قله حيا لكن ليهودي يهودي ̮\nMasked sentence-> بس ريال عن عبدالله بن عباس رضي الله [MASK] عنه قال قال النبي لعن الله اليهود ثلاثا ان الله حرم عليهم الشحوم فباعوها واكلوا اثمانها وان الله اذا حرم علي قوم اكل شيء حرم عليهم ثمنه رواه ابو داود 3488 وصححه الالباني\nMasked sentence-> اعطوني خطاب واحد لباسيل لم يذكر فيه المسيحيه والمارونيه بلبنان بينما بكل عمري لم اسمع [MASK] من الرءيس بري رغم خوضه حرب لبنان التي فرضت علينا كلمه شيعي او مسلم جبران بيقول مسيحي وماروني اكثر ما بيذكر لبنان ولهذا الاناء نضح بما فيه نبيه بري خط احمر\nMasked sentence-> لبنان اولا واخيرا فشل مخطتكم بالفتنه سنيه شعييه ولم ولن تفلحو بالفتنه المسيحيه الشيعيه ما دام هناك [MASK] قاده امثال نبيه بري والسيد حسن وجنرال\nMasked sentence-> المانيا التحالف المسيحي يتوصل مع [MASK] الاشتراكيين لاتفاق بشان لم شمل اسر اللاجءين\nMasked sentence-> المانيا التحالف المسيحي يتوصل مع الاشتراكيين لاتفاق بشان لم [MASK] شمل اسر اللاجءين\nMasked sentence-> 26 فلما فتحت الخلافه القسطنطينيه وهي مركز ديني مهم في المسيحيه اراد البابا الرد بنفس المقدار فكلف الاسبان والبرتغاليين باحتلال المدينه ومكه فتحالوا مع دوله فارس ضد الخلافه التي اضطرت للحرب مع فارس ونفس الشيء [MASK] تحالفوا مع المغول ومع الصليبيين بما يءيد فرضيتنا في الدافعيه السياسيه\nMasked sentence-> يلا ليش ما [MASK] بينشال الغطا المسيحي عن السلاح ومنشوف كيف رح تمشي الامور\nMasked sentence-> ان تشرب قهوتك مع صديقك اليهودي ثم تذهبان لزياره صديقكما الملحد فتلقيان التحيه علي باءعه الورد الهندوسيه [MASK] فتجدان المسلم يمازح المسيحي والشيعي يصلح ماذنه المسجد السني هل سيغضب الله هذا الامر\nMasked sentence-> ان تشرب قهوتك مع صديقك اليهودي ثم تذهبان لزياره صديقكما الملحد فتلقيان التحيه علي باءعه الورد الهندوسيه فتجدان المسلم يمازح المسيحي والشيعي يصلح ماذنه المسجد [MASK] السني هل سيغضب الله هذا الامر\nMasked sentence-> ان تشرب قهوتك مع صديقك اليهودي ثم تذهبان لزياره صديقكما الملحد [MASK] فتلقيان التحيه علي باءعه الورد الهندوسيه فتجدان المسلم يمازح المسيحي والشيعي يصلح ماذنه المسجد السني هل سيغضب الله هذا الامر\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/4174790004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Masked sentence->\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_mask_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0maugmented_text_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0maugmented_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmented_text_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m         )\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m         )\n\u001b[1;32m   1030\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 )\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}